---
title: "202116927 오준석 SVM과 k-NN"
author: "202116927 오준석"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
library(dplyr)
library(e1071)
library(ggplot2)
library(tidyr)
```

ULCA admission의 SVM과 k-NN
ULCA 데이터의 모델을 만들기 위해 전처리를 진행
```{r}
ulca <- read.csv("binary.csv")
ulca$rank <- as.factor(ulca$rank)
ulca$admit <- as.factor(ulca$admit)
```

세 개의 변수가 합격에 미치는 영향을 알아보고자 함
```{r}
s <- svm(admit~., data=ulca)
print(s)
acc = table(predict(s, ulca), data=ulca$admit)
acc
acc1 <- sum((acc["0", "0"]+acc["1", "1"])/sum(acc))
```

```{r}
s <- svm(admit~., data=ulca, kernal = "polynomial")
print(s)
acc = table(predict(s, ulca), data=ulca$admit)
acc
acc2 <- sum((acc["0", "0"]+acc["1", "1"])/sum(acc))
```

radial basis 커널을 사용한 SVM과 polynomial 커널을 사용한 SVM의 정확도는 0.7175임.

```{r}
s <- svm(admit~., data=ulca, kernal = "polynomial", cost=100)
print(s)
acc = table(predict(s, ulca), data=ulca$admit)
acc
acc3 <- sum((acc["0", "0"]+acc["1", "1"])/sum(acc))
```


```{r}
s <- svm(admit~., data=ulca, cost=100)
print(s)
acc = table(predict(s, ulca), data=ulca$admit)
acc
acc4 <- sum((acc["0", "0"]+acc["1", "1"])/sum(acc))
```

```{r}
accuracy <- data.frame(acc1, acc2, acc3, acc4)
accuracy <- accuracy%>%gather(key=acc, value=accuracy)
accuracy%>%ggplot(aes(acc, accuracy))+geom_point()
```

polynomial 커널을 사용하고 cost를 100으로 설정한 SVM과 radial basis 커널을 사용한 SVM의 정확도는 0.7525로, cost를 설정하지 않았을 때보다 4%가량의 정확도가 오름

```{r}
library(class)
library(caret)
```

```{r}
train <- ulca
test <- data.frame(gre = c(800, 760, 540, 740), gpa = c(4.00, 3.52, 2.80, 3.75), rank = c("1", "4", "2", "3"))
k = knn(train[, 2:4], test, train$admit, k=5)
k
```

ulca 데이터의 k-NN 모델을 k를 바꾸며 제작
```{r}
train <- ulca
n=400
ulca1 <- sample(1:n, size=n*3/4)
ulca_train <- ulca[ulca1, -1]
ulca_test <- ulca[-ulca1, -1]
trainLabels <- ulca[ulca1, 1]
testLabels <- ulca[-ulca1, 1]
k1 <- knn(ulca_train, ulca_test, trainLabels, k=1)
acc1 <- sum(k1==testLabels)/100
k2 <- knn(ulca_train, ulca_test, trainLabels, k=5)
acc2 <- sum(k2==testLabels)/100
k3 <- knn(ulca_train, ulca_test, trainLabels, k=10)
acc3 <- sum(k3==testLabels)/100
k4 <- knn(ulca_train, ulca_test, trainLabels, k=100)
acc4 <- sum(k4==testLabels)/100
```

제작한 모델의 정확성을 시각화
```{r}
accuracy <- data.frame(acc1, acc2, acc3, acc4)
accuracy <- accuracy%>%gather(key=acc, value=accuracy)
accuracy%>%ggplot(aes(acc, accuracy))+geom_point()
```

k가 100일 때 0.7 이상의 정확성을 가짐.




colon의 SVM과 k-NN
colon 데이터의 모델을 만들기 위해 전처리
```{r}
library(survival)
colon <- colon[c(TRUE, FALSE), ]
colon <- colon[ , c(-1, -2, -15, -16)]
colon <- na.omit(colon)
colon$status <- as.factor(colon$status)
```

colon의 SVM
```{r}
s <- svm(status~. , data=colon)
print(s)
acc <- table(predict(s, colon), colon$status)
acc1 <- sum(acc["0", "0"]+acc["1", "1"])/sum(acc)
acc
acc1
```
```{r}
s <-svm(status~., data=colon, kernal='polynomial')
print(s)
acc <-table(predict(s, colon), colon$status)
acc2 <- sum(acc["0", "0"]+acc["1", "1"])/sum(acc)
acc
acc2
```
```{r}
s <- svm(status~., data=colon, cost=100)
print(s)
acc <- table(predict(s, colon), colon$status)
acc3 <- sum(acc["0", "0"]+acc["1", "1"])/sum(acc)
acc
acc3
```
```{r}
s <- svm(status~., data=colon, cost=100, kernal='polynomial')
print(s)
acc <- table(predict(s, colon), colon$status)
acc4 <- sum(acc["0", "0"]+acc["1", "1"])/sum(acc)
acc
acc4
```
```{r}
accuracy <- data.frame(acc1, acc2, acc3, acc4)
accuracy <- accuracy%>%gather(key=acc, value=accuracy)
accuracy%>%ggplot(aes(acc, accuracy))+geom_point()
```
colon의 SVM에서 정확도는 커널의 종류와 관계 없고, cost가 100으로 설정되었을 때가 20%가량 높음


colon의 k-NN 모델을 만듦
여기서 rx는 범주형 변수로, 이를 이용해 k-NN 모델을 만든다면 수치형 데이터로 변환하는 과정에서 NA에 의한 오류가 발생함. 이를 해결하기 위해 치료를 진행하지 않았을 때인 obs를 0으로, 그 외의 범주를 1로 설정함.
```{r}
colon$rx <- ifelse(colon$rx=="obs", 0, 1)
train <- colon
str(colon)
n=888
colon1 <- sample(1:n, size=3/4*n)
colon_train <- colon[colon1, -8]
colon_test <- colon[-colon1, -8]
trainLabels <- colon[colon1, 8]
testLabels <- colon[-colon1, 8]
k1 <- knn(colon_train, colon_test, trainLabels, k=1)
acc1 <- sum(k1==testLabels)/222
k2 <- knn(colon_train, colon_test, trainLabels, k=5)
acc2 <- sum(k2==testLabels)/222
k3 <- knn(colon_train, colon_test, trainLabels, k=10)
acc3 <- sum(k3==testLabels)/222
k4 <- knn(colon_train, colon_test, trainLabels, k=100)
acc4 <- sum(k4==testLabels)/222
```
k 값에 따른 정확성을 시각화, 평가
```{r}
acc <- data.frame(acc1, acc2, acc3, acc4)
acc <- acc%>%gather(key=acc, value=accuracy)
acc%>%ggplot(aes(acc, accuracy))+geom_point()
```
k가 1일 때 이외에는 정확도가 수시로 변해 어느 k값이 더 좋은지 단정지을 수 없으며, 정확도가 60%정도로 매우 낮음.


voice 데이터의 SVM과 k-NN 모델
voice 데이터로 모델링을 하기 위해 전처리
```{r}
voice <- read.csv("voice.csv")
table(is.na(voice))
voice$label <- as.factor(voice$label)
```
voice의 SVM
```{r}
s <- svm(label~., data=voice)
acc <- table(predict(s, voice), voice$label)
acc1 <- sum(acc["female", "female"]+acc["male", "male"])/sum(acc)
acc
acc1
```

```{r}
s <- svm(label~., data=voice, kernal="polynomial")
acc <- table(predict(s, voice), voice$label)
acc2 <- sum(acc["female", "female"]+acc["male", "male"])/sum(acc)
acc
acc2
```

```{r}
s <- svm(label~., data=voice, cost=100)
acc <- table(predict(s, voice), voice$label)
acc3 <- sum(acc["female", "female"]+acc["male", "male"])/sum(acc)
acc
acc3
```

```{r}
s <- svm(label~., data=voice, kernal="polynomial", cost=100)
acc <- table(predict(s, voice), voice$label)
acc4<- sum(acc["female", "female"]+acc["male", "male"])/sum(acc)
acc
acc4
```

각 SVM의 정확도를 데이터 프레임으로 만들어 시각화, 평가
```{r}
accuracy <- data.frame(acc1, acc2, acc3, acc4)
accuracy <- accuracy%>%gather(key=acc, value=accuracy)
accuracy%>%ggplot(aes(acc, accuracy))+geom_point()
```
voice의 SVM의 정확도는 커널의 종류와 관계 없으며, cost를 100으로 설정했을 때 모든 오류가 사라지는 것을 확인할 수 있음

voice의 k-NN
```{r}
test <- voice
n=3168
voice1 <- sample(1:n, size=2/3*n)
voice_train <- voice[voice1, -21]
voice_test <- voice[-voice1, -21]
trainLabels <- voice[voice1, 21]
testLabels <- voice[-voice1, 21]
k1 <- knn(voice_train, voice_test, trainLabels, k=1)
acc1 <- sum(k1==testLabels)/1056
k2 <- knn(voice_train, voice_test, trainLabels, k=5)
acc2 <- sum(k2==testLabels)/1056
k3 <- knn(voice_train, voice_test, trainLabels, k=10)
acc3 <- sum(k3==testLabels)/1056
k4 <- knn(voice_train, voice_test, trainLabels, k=100)
acc4 <- sum(k4==testLabels)/1056
```

voice의 k-NN을 데이터 프레임으로 만들어 시각화하고 평가
```{r}
accuracy <- data.frame(acc1, acc2, acc3, acc4)
accuracy <- accuracy%>%gather(key=acc, value=accuracy)
accuracy%>%ggplot(aes(acc, accuracy))+geom_point()
```
voice의 k-NN은 k 값이 5일 때 대체로 가장 높은 정확도를 가지며, 정확도는 70% 내외로 SVM에 비해 낮은 편임.

